[["index.html", "Python and R Welcome", " Python and R Clay Ford, Jacob Goldstein-Greenwood, Oyinkansola Adenekan, Samantha Lomuscio 2021-10-05 Welcome This book provides parallel examples in Python and R to help users of one platform more easily transition to the other. "],["basics.html", "Chapter 1 Basics 1.1 Math 1.2 Assignment 1.3 Printing a value 1.4 Packages 1.5 Logic 1.6 Generating a sequence of values 1.7 Calculating means and medians", " Chapter 1 Basics This chapter covers the very basics of Python and R. 1.1 Math Mathematical operators are the same except for exponents, integer division, and remainder division (modulo). Python Python uses ** for exponentiation, // for integer division, and % for remainder division. &gt; 3**2 9 &gt; 5 // 2 2 &gt; 5 % 2 1 In Python, the + operator can also be used to combine strings. See this TBD section. R Python uses ^ for exponentiation, %/% for integer division, and %% for remainder division. &gt; 3^2 [1] 9 &gt; 5 %/% 2 [1] 2 &gt; 5 %% 2 [1] 1 1.2 Assignment Python uses = for assignment while R can use either = or &lt;- for assignment. The latter “assignment arrow” is preferred in most R style guides to distinguish it between assignment and setting the value of a function argument. According to R’s documentation, “The operator &lt;- can be used anywhere, whereas the operator = is only allowed at the top level (e.g., in the complete expression typed at the command prompt) or as one of the subexpressions in a braced list of expressions.” See ?assignOps. Python &gt; x = 12 R &gt; x &lt;- 12 1.3 Printing a value To see the value of an object created via assignment, you can simply enter the object at the console and hit enter for both Python and R, though it is common in Python to explicitly use the print() function. Python &gt; x 12 R &gt; x [1] 12 1.4 Packages User-created functions can be bundled and distributed as packages. Packages need to be installed only once. Thereafter they’re “imported” (Python) or “loaded” (R) in each new session when needed. Packages with large user bases are often updated to add functionality and fix bugs. The updates are not automatically installed. Staying apprised of library/package updates can be challenging. Some suggestions are following developers on Twitter, signing up for newsletters, or periodically checking to see what updates are available. Packages often depend on other packages. These are known as “dependencies.” Sometimes packages are updated to accommodate changes to other packages they depend on. Python R The main repository for R packages is the Comprehensive R Archive Network (CRAN). Another repository is Bioconductor, which provides tools for working with genomic data. Many packages are also distributed on GitHub. To install packages from CRAN use the install.packages() function. In RStudio, you can also go to Tools…Install Packages… for a dialog that will auto-complete package names as you type. &gt; # install the vcd package, a package for Visualizing Categorical Data &gt; install.packages(&quot;vcd&quot;) &gt; &gt; # load the package &gt; library(vcd) &gt; &gt; # see which packages on your computer have updates available &gt; old.packages() &gt; &gt; # download and install available package updates; &gt; # set ask = TRUE to verify installation of each package &gt; update.packages(ask = FALSE) To install R packages from GitHub use the install_github() function from the devtools package. You need to include the username of the repo owner followed by a forward slash and the name of the package. Typing two colons between a package and a function in the package allows you to use that function without loading the package. That’s how we use the install_github() below. &gt; install.packages(&quot;devtools&quot;) &gt; devtools::install_github(&quot;username/packagename&quot;) Occasionally when installing package updates you will be asked “Do you want to install from sources the package which needs compilation?” R packages on CRAN are compiled for Mac and Windows operating systems. That can take a day or two after a package has been submitted to CRAN. If you try to install a package that has not been compiled then you’ll get asked the question above. If you click Yes, R will try to compile the package on your computer. This will only work if you have the required build tools on your computer. For Windows this means having Rtools installed. Mac users should already have the necessary build tools. Unless you absolutely need the latest version of a package, it’s probably fine to click No. 1.5 Logic Python and R share the same operators for making comparisons: == (equals) != (not equal to) &lt; (less than) &lt;= (less than or equal to) &gt; (greater than) &gt;= (greater than or equal to) Likewise they share the same operators for logical AND and OR: &amp; (AND) | (OR) However R also has &amp;&amp; and || operators for programming control-flow. Python and R have different operators for negation and xor (exclusive OR). Python R 1.6 Generating a sequence of values In Python, one option for generating a sequence of values is arange() from NumPy. In R, a common approach is to use seq(). The sequences can be incremented by indicating a step argument in arange() or a by argument in seq(). Be aware that the end of the start/stop interval in arange() is open, but the from/to interval in seq() is closed. Python &gt; import numpy as np + x = np.arange(start = 1, stop = 11, step = 2) + x array([1, 3, 5, 7, 9]) R &gt; x &lt;- seq(from = 1, to = 11, by = 2) &gt; x [1] 1 3 5 7 9 11 1.7 Calculating means and medians The NumPy Python library has functions for calculating means and medians, and base R has functions for doing the same. Python Mean, using function from NumPy library &gt; import numpy as np + x = [90, 105, 110] + x_avg = np.mean(x) + print(x_avg) 101.66666666666667 Median, using function from NumPy library &gt; x = [98, 102, 20, 22, 304] + x_med = np.median(x) + print(x_med) 98.0 R Mean, using function from base R &gt; x &lt;- c(90, 105, 110) &gt; x_avg &lt;- mean(x) &gt; x_avg [1] 101.6667 Median, using function from base R &gt; x &lt;- c(98, 102, 20, 22, 304) &gt; x_med &lt;- median(x) &gt; x_med [1] 98 "],["data-structures.html", "Chapter 2 Data Structures 2.1 One-dimensional data 2.2 Two-dimensional data 2.3 Three-dimensional and higher data", " Chapter 2 Data Structures This chapter compares and contrasts data structures in Python and R. 2.1 One-dimensional data A one-dimensional data structure can be visualized as a column in a spreadsheet or as a list of values. Python R In R a one-dimensional data structure is called a vector. We can create a vector using the c() function. A vector in R can only contain one type of data (all numbers, all strings, etc). The columns of data frames are vectors. If multiple types of data are put into a vector, the data will be coerced according to the hierarchy logical &lt; integer &lt; double &lt; complex &lt; character. This means if you mix, say, integers and character data, all the data will be coerced to character. &gt; x1 &lt;- c(23, 43, 55) &gt; x1 [1] 23 43 55 &gt; # all values coerced to character &gt; x2 &lt;- c(23, 43, &#39;hi&#39;) &gt; x2 [1] &quot;23&quot; &quot;43&quot; &quot;hi&quot; Values in a vector can be accessed by position using indexing brackets. &gt; # extract the 2nd value &gt; x1[2] [1] 43 &gt; # extract the 2nd and 3rd value &gt; x1[2:3] [1] 43 55 2.2 Two-dimensional data Two-dimensional data are rectangular in nature, consisting of rows and columns. These can be the type of data you might find in a spreadsheet with a mix of data types in columns; they can also be matrices as you might encounter in matrix algebra. Python R Two-dimensional data structures in R include the matrix and data frame. A matrix can contain only one data type. A data frame can contain multiple vectors each of which can consist of different data types. Create a matrix with the matrix() function. Create a data frame with the data.frame() function. Most imported data comes into R as a data frame. &gt; # matrix; populated down by column by default &gt; m &lt;- matrix(data = c(1,3,5,7), nrow = 2, ncol = 2) &gt; m [,1] [,2] [1,] 1 5 [2,] 3 7 &gt; # data frame &gt; d &lt;- data.frame(name = c(&quot;Rob&quot;, &quot;Cindy&quot;), + age = c(35, 37)) &gt; d name age 1 Rob 35 2 Cindy 37 Values in a matrix and data frame can be accessed by position using indexing brackets. The first number(s) refers to rows; the second number(s) refers to columns. Leaving row or column numbers empty selects all rows or columns. &gt; # extract value in row 1, column 2 &gt; m[1,2] [1] 5 &gt; # extract values in row 2 &gt; d[2,] name age 2 Cindy 37 2.3 Three-dimensional and higher data Three-dimensional and higher data can be visualized as multiple rectangular structures stratified by extra variables. These are sometimes referred to as arrays. Analysts usually prefer two-dimensional data frames to arrays. Data frames can accommodate multidimensional data by including the additional dimensions as variables. Python R The array() function in R can create three-dimensional and higher data structures. Specify the dimension number and size using the dim argument. Below we specify 2 rows, 3 columns, and 2 strata using a vector: c(2,3,2). This creates a three-dimensional data structure. The data are simply the numbers 1 through 12. &gt; a1 &lt;- array(data = 1:12, dim = c(2,3,2)) &gt; a1 , , 1 [,1] [,2] [,3] [1,] 1 3 5 [2,] 2 4 6 , , 2 [,1] [,2] [,3] [1,] 7 9 11 [2,] 8 10 12 Values in arrays can be accessed by position using indexing brackets. &gt; # extract value in row 1, column 2, strata 1 &gt; a1[1,2,1] [1] 3 &gt; # extract column 2 in both strata &gt; # result is returned as matrix &gt; a1[,2,] [,1] [,2] [1,] 3 9 [2,] 4 10 The dimensions can be named using the dimnames() function. Notice the names must be a list. &gt; dimnames(a1) &lt;- list(&quot;X&quot; = c(&quot;x1&quot;, &quot;x2&quot;), + &quot;Y&quot; = c(&quot;y1&quot;, &quot;y2&quot;, &quot;y3&quot;), + &quot;Z&quot; = c(&quot;z1&quot;, &quot;z2&quot;)) &gt; a1 , , Z = z1 Y X y1 y2 y3 x1 1 3 5 x2 2 4 6 , , Z = z2 Y X y1 y2 y3 x1 7 9 11 x2 8 10 12 The as.data.frame.table() function can collapse an array into a two-dimensional structure that may be easier to use with standard statistical and graphical routines. The responseName argument allows you to provide a suitable column name for the values in the array. &gt; as.data.frame.table(a1, responseName = &quot;value&quot;) X Y Z value 1 x1 y1 z1 1 2 x2 y1 z1 2 3 x1 y2 z1 3 4 x2 y2 z1 4 5 x1 y3 z1 5 6 x2 y3 z1 6 7 x1 y1 z2 7 8 x2 y1 z2 8 9 x1 y2 z2 9 10 x2 y2 z2 10 11 x1 y3 z2 11 12 x2 y3 z2 12 "],["importing-data.html", "Chapter 3 Importing Data 3.1 CSV 3.2 XLS/XLSX (Excel) 3.3 JSON 3.4 XML", " Chapter 3 Importing Data This chapter reviews importing external data into Python and R, including CSV, Excel, and other structured data files. There is often more than one way to import data into Python and R. The examples below highlight one way that we frequently see used. The data we use for demonstration is New York State Math Test Results by Grade from 2006 - 2011, downloaded from data.gov on September 30, 2021. 3.1 CSV Comma separated value (CSV) files are text files with fields separated by commas. They are useful for “rectangular” data where rows represent observations and columns represent variables or features. Python &gt; import pandas + d = pandas.read_csv(&#39;data/ny_math_test.csv&#39;) + d.loc[0:2, [&quot;Grade&quot;, &quot;Year&quot;, &quot;Mean Scale Score&quot;]] Grade Year Mean Scale Score 0 3 2006 700 1 4 2006 699 2 5 2006 691 R There are many ways to import a csv file. A common way is to use the base R function read.csv(). &gt; d &lt;- read.csv(&quot;data/ny_math_test.csv&quot;) &gt; d[1:3, c(&quot;Grade&quot;, &quot;Year&quot;, &quot;Mean.Scale.Score&quot;)] Grade Year Mean.Scale.Score 1 3 2006 700 2 4 2006 699 3 5 2006 691 Notice the spaces in the column names have been replaced with periods. Two packages that provide alternatives to read.csv() are readr and data.table. The readr function read_csv() returns a tibble. The data.table function fread() returns a data.table. 3.2 XLS/XLSX (Excel) Excel files are native to Microsoft Excel. Prior to 2007, Excel files had an extension of XLS. With the launch of Excel 2007, the extension was changed to XLSX. Excel files can have multiple sheets of data. This needs to be accounted for when importing into Python and R. Python R readxl is a well-documented and actively maintained package for importing Excel files into R. The workhorse function is read_excel(). The sheet argument allows you to specify which sheet you want to import. You can specify sheet by its ordering or by its name. Since this Excel file only has one sheet we do not need to use the argument. &gt; # read in the 2nd sheet &gt; library(readxl) &gt; d_xls &lt;- read_excel(&quot;data/ny_math_test.xlsx&quot;) &gt; d_xls[1:3, c(&quot;Grade&quot;, &quot;Year&quot;, &quot;Mean Scale Score&quot;)] # A tibble: 3 × 3 Grade Year `Mean Scale Score` &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; 1 3 2006 700 2 4 2006 699 3 5 2006 691 The result is a tibble, a tidyverse data frame. It’s worth noting we can use the range argument to specify a range of cells to import. For example, if the top left corner of the data was B5 and the bottom right corner of the data was J54, we could enter range=\"B5:J54\" to just import that section of data. 3.3 JSON JSON (JavaScript Object Notation) is a flexible format for storing data. JSON files are text and can be viewed in any text editor. Because of their flexibility JSON files can be quite complex in the way they store data. Therefore there is no one-size-fits-all for importing JSON files into Python or R. Python R jsonlite is one of several R packages available for importing JSON files into R. The read_json() function takes a JSON file and returns a list or data frame depending on the structure of the data file and its arguments. We set simplifyVector = TRUE so the data is simplified into a matrix. &gt; library(jsonlite) &gt; d_json &lt;- read_json(&#39;data/ny_math_test.json&#39;, simplifyVector = TRUE) The d_json object is a list with two elements: “meta” and “data.” The “data” element is a matrix that contains the data of interest. The “meta” element contains the column names for the data (among much else). Notice we had to “drill down” in the list to find the column names. We assign column names to the matrix using the colnames() function and then convert the matrix to a data frame using the as.data.frame() function. &gt; colnames(d_json$data) &lt;- d_json$meta$view$columns$fieldName &gt; d_json &lt;- as.data.frame(d_json$data) &gt; d_json[1:3,c(&quot;grade&quot;, &quot;year&quot;, &quot;mean_scale_score&quot;)] grade year mean_scale_score 1 3 2006 700 2 4 2006 699 3 5 2006 691 3.4 XML XML (eXtensible Markup Language) is a markup language that was designed to store data. XML files are text and can be viewed in any text editor or a web browser. Because of their flexibility XML files can be quite complex in the way they store data. Therefore there is no one-size-fits-all for importing XML files into Python or R. Python R xml2 is a relatively small but powerful package for importing and working with XML files. The read_xml() function imports an XML file and returns a list of pointers to XML nodes. There are a number of ways to proceed once you import an XML file, such as using the xml_find_all() function to find nodes that match an xpath expression. Below we take a simple approach and convert the XML nodes into a list using the as_list() function that is part of the xml2 package. Once we have the XML nodes in a list, we can use the bind_rows() function in the dplyr package to create a data frame. Notice we have to drill down into the list to select the element that contains the data. After this we need to do one more thing: unlist each the columns into vectors. We do this by applying the unlist function to each column of d. We save the result by assigning to d[], which overwrites each element (or column) of d with the unlisted result. &gt; library(xml2) &gt; d_xml &lt;- read_xml(&#39;data/ny_math_test.xml&#39;) &gt; d_list &lt;- as_list(d_xml) &gt; d &lt;- dplyr::bind_rows(d_list$response$row) &gt; d[] &lt;- lapply(d, unlist) &gt; d[1:3,c(&quot;grade&quot;, &quot;year&quot;, &quot;mean_scale_score&quot;)] # A tibble: 3 × 3 grade year mean_scale_score &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; 1 3 2006 700 2 4 2006 699 3 5 2006 691 The result is a tibble, a tidyverse data frame. We would most likely want to proceed to converting certain columns to numeric. "],["data-manipulation.html", "Chapter 4 Data Manipulation 4.1 Names of variables and their types 4.2 Access variables 4.3 Rename variables 4.4 Create, replace and remove variables 4.5 Create strings from numbers 4.6 Create numbers from strings 4.7 Change case 4.8 Drop duplicate rows 4.9 Randomly sample rows", " Chapter 4 Data Manipulation This chapter looks at various strategies for modifying and deriving variables in data. Unless otherwise stated, examples are for DataFrames (Python) and data frames (R) and use the mtcars data frame that is included with R. &gt; # Python + import pandas + mtcars = pandas.read_csv(&#39;data/mtcars.csv&#39;) &gt; # R &gt; data(mtcars) &gt; # drop row names to match Python version of data &gt; rownames(mtcars) &lt;- NULL 4.1 Names of variables and their types View and inspect the names of variables and their type (numeric, string, logical, etc.) This is useful to ensure that variables have the expected type. Python The .info() function in pandas lists information on the DataFrame. Setting the argument verbose to True prints the name of the columns, their length excluding NULL values, and their data type (dtype) in a table. The function lists the unique data types in the DataFrame, and it prints how much memory the DataFrame takes up. &gt; mtcars.info(verbose=True) &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 32 entries, 0 to 31 Data columns (total 11 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 mpg 32 non-null float64 1 cyl 32 non-null int64 2 disp 32 non-null float64 3 hp 32 non-null int64 4 drat 32 non-null float64 5 wt 32 non-null float64 6 qsec 32 non-null float64 7 vs 32 non-null int64 8 am 32 non-null int64 9 gear 32 non-null int64 10 carb 32 non-null int64 dtypes: float64(5), int64(6) memory usage: 2.9 KB By default, the verbose argument is set to False. Then, the function lists the unique data types in the DataFrame, and it prints how much memory the DataFrame takes up. This setting excludes the table describing each column. &gt; mtcars.info() &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 32 entries, 0 to 31 Data columns (total 11 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 mpg 32 non-null float64 1 cyl 32 non-null int64 2 disp 32 non-null float64 3 hp 32 non-null int64 4 drat 32 non-null float64 5 wt 32 non-null float64 6 qsec 32 non-null float64 7 vs 32 non-null int64 8 am 32 non-null int64 9 gear 32 non-null int64 10 carb 32 non-null int64 dtypes: float64(5), int64(6) memory usage: 2.9 KB R The str() function in R lists the names of the variables, their type, the first few values, and the dimensions of the data frame. &gt; str(mtcars) &#39;data.frame&#39;: 32 obs. of 11 variables: $ mpg : num 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... $ cyl : num 6 6 4 6 8 6 8 4 4 6 ... $ disp: num 160 160 108 258 360 ... $ hp : num 110 110 93 110 175 105 245 62 95 123 ... $ drat: num 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... $ wt : num 2.62 2.88 2.32 3.21 3.44 ... $ qsec: num 16.5 17 18.6 19.4 17 ... $ vs : num 0 0 1 1 0 1 0 1 1 1 ... $ am : num 1 1 1 0 0 0 0 0 0 0 ... $ gear: num 4 4 4 3 3 3 3 4 4 4 ... $ carb: num 4 4 1 1 2 1 4 2 2 4 ... To see just the names of the data frame, use the names() function. &gt; names(mtcars) [1] &quot;mpg&quot; &quot;cyl&quot; &quot;disp&quot; &quot;hp&quot; &quot;drat&quot; &quot;wt&quot; &quot;qsec&quot; &quot;vs&quot; &quot;am&quot; &quot;gear&quot; &quot;carb&quot; To see just the dimensions of the data frame, use the dim() function. It returns the number of rows and columns, respectively. &gt; dim(mtcars) [1] 32 11 4.2 Access variables How to work with a specific column of data. Python The period operator . provides access to a column in a DataFrame as a vector. This returns pandas series. A pandas series can do everything a numpy array can do. &gt; mtcars.mpg 0 21.0 1 21.0 2 22.8 3 21.4 4 18.7 5 18.1 6 14.3 7 24.4 8 22.8 9 19.2 10 17.8 11 16.4 12 17.3 13 15.2 14 10.4 15 10.4 16 14.7 17 32.4 18 30.4 19 33.9 20 21.5 21 15.5 22 15.2 23 13.3 24 19.2 25 27.3 26 26.0 27 30.4 28 15.8 29 19.7 30 15.0 31 21.4 Name: mpg, dtype: float64 Indexing also provides access to columns as a pandas Series. Single and double quotations both work. &gt; mtcars[&#39;mpg&#39;] 0 21.0 1 21.0 2 22.8 3 21.4 4 18.7 5 18.1 6 14.3 7 24.4 8 22.8 9 19.2 10 17.8 11 16.4 12 17.3 13 15.2 14 10.4 15 10.4 16 14.7 17 32.4 18 30.4 19 33.9 20 21.5 21 15.5 22 15.2 23 13.3 24 19.2 25 27.3 26 26.0 27 30.4 28 15.8 29 19.7 30 15.0 31 21.4 Name: mpg, dtype: float64 Operations on numpy arrays are faster than operations on pandas series. But using pandas series should be fine, in terms of performance, in many cases. This is important for large data sets on which many operations are performed. The .values function returns a numpy array. &gt; mtcars[&#39;mpg&#39;].values array([21. , 21. , 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8, 16.4, 17.3, 15.2, 10.4, 10.4, 14.7, 32.4, 30.4, 33.9, 21.5, 15.5, 15.2, 13.3, 19.2, 27.3, 26. , 30.4, 15.8, 19.7, 15. , 21.4]) Double indexing returns a pandas DataFrame, instead of a numpy array or pandas series. &gt; mtcars[[&#39;mpg&#39;]] mpg 0 21.0 1 21.0 2 22.8 3 21.4 4 18.7 5 18.1 6 14.3 7 24.4 8 22.8 9 19.2 10 17.8 11 16.4 12 17.3 13 15.2 14 10.4 15 10.4 16 14.7 17 32.4 18 30.4 19 33.9 20 21.5 21 15.5 22 15.2 23 13.3 24 19.2 25 27.3 26 26.0 27 30.4 28 15.8 29 19.7 30 15.0 31 21.4 The head() and tail() functions return the first 5 or last 5 values. Use the n argument to change the number of values. This function works on numpy array, pandas series and pandas DataFrames. &gt; # first 6 values + mtcars.mpg.head() 0 21.0 1 21.0 2 22.8 3 21.4 4 18.7 Name: mpg, dtype: float64 &gt; # last row of DataFrame + mtcars.tail(n=1) mpg cyl disp hp drat wt qsec vs am gear carb 31 21.4 4 121.0 109 4.11 2.78 18.6 1 1 4 2 R The dollar sign operator, $, provides access to a column in a data frame as a vector. &gt; mtcars$mpg [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7 15.0 [32] 21.4 Double indexing brackets also provide access to columns as a vector. &gt; mtcars[[&quot;mpg&quot;]] [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7 15.0 [32] 21.4 Single indexing brackets work as well, but return a data frame instead of a vector (if used with a data frame). &gt; mtcars[&quot;mpg&quot;] mpg 1 21.0 2 21.0 3 22.8 4 21.4 5 18.7 6 18.1 7 14.3 8 24.4 9 22.8 10 19.2 11 17.8 12 16.4 13 17.3 14 15.2 15 10.4 16 10.4 17 14.7 18 32.4 19 30.4 20 33.9 21 21.5 22 15.5 23 15.2 24 13.3 25 19.2 26 27.3 27 26.0 28 30.4 29 15.8 30 19.7 31 15.0 32 21.4 Single indexing brackets also allow selection of rows when used with a comma. The syntax is rows, columns &gt; # first three rows &gt; mtcars[1:3, &quot;mpg&quot;] [1] 21.0 21.0 22.8 Finally single indexing brackets allow us to select multiple columns. Request columns either by name or position using a vector. &gt; mtcars[c(&quot;mpg&quot;, &quot;cyl&quot;)] mpg cyl 1 21.0 6 2 21.0 6 3 22.8 4 4 21.4 6 5 18.7 8 6 18.1 6 7 14.3 8 8 24.4 4 9 22.8 4 10 19.2 6 11 17.8 6 12 16.4 8 13 17.3 8 14 15.2 8 15 10.4 8 16 10.4 8 17 14.7 8 18 32.4 4 19 30.4 4 20 33.9 4 21 21.5 4 22 15.5 8 23 15.2 8 24 13.3 8 25 19.2 8 26 27.3 4 27 26.0 4 28 30.4 4 29 15.8 8 30 19.7 6 31 15.0 8 32 21.4 4 &gt; # same as mtcars[1:2] The head() and tail() functions return the first 6 or last 6 values. Use the n argument to change the number of values. They work with vectors or data frames. &gt; # first 6 values &gt; head(mtcars$mpg) [1] 21.0 21.0 22.8 21.4 18.7 18.1 &gt; # last row of data frame &gt; tail(mtcars, n = 1) mpg cyl disp hp drat wt qsec vs am gear carb 32 21.4 4 121 109 4.11 2.78 18.6 1 1 4 2 4.3 Rename variables How to rename variables or “column headers.” Python R Variable names can be changed by their index (ie, order of columns in the data frame). Below the second column is “cyl.” We change the name to “cylinder.” &gt; names(mtcars)[2] [1] &quot;cyl&quot; &gt; names(mtcars)[2] &lt;- &quot;cylinders&quot; &gt; names(mtcars) [1] &quot;mpg&quot; &quot;cylinders&quot; &quot;disp&quot; &quot;hp&quot; &quot;drat&quot; &quot;wt&quot; &quot;qsec&quot; &quot;vs&quot; &quot;am&quot; &quot;gear&quot; &quot;carb&quot; Variable names can also be changed by conditional match. Below we find the variable name that matches “drat” and change to “axle_ratio.” &gt; names(mtcars)[names(mtcars) == &quot;drat&quot;] [1] &quot;drat&quot; &gt; names(mtcars)[names(mtcars) == &quot;drat&quot;] &lt;- &quot;axle_ratio&quot; &gt; names(mtcars) [1] &quot;mpg&quot; &quot;cylinders&quot; &quot;disp&quot; &quot;hp&quot; &quot;axle_ratio&quot; &quot;wt&quot; &quot;qsec&quot; &quot;vs&quot; &quot;am&quot; &quot;gear&quot; &quot;carb&quot; More than one variable name can be changed using a vector of positions or matches. &gt; names(mtcars)[c(6,8)] &lt;- c(&quot;weight&quot;, &quot;engine&quot;) &gt; &gt; # or &gt; # names(mtcars)[names(mtcars) %in% c(&quot;wt&quot;, &quot;vs&quot;)] &lt;- c(&quot;weight&quot;, &quot;engine&quot;) &gt; &gt; names(mtcars) [1] &quot;mpg&quot; &quot;cylinders&quot; &quot;disp&quot; &quot;hp&quot; &quot;axle_ratio&quot; &quot;weight&quot; &quot;qsec&quot; &quot;engine&quot; &quot;am&quot; &quot;gear&quot; &quot;carb&quot; See also the rename() function in the dplyr package. 4.4 Create, replace and remove variables We often need to create variables that are functions of other variables, or replace existing variables with an updated version. Python R Adding a new variable name after the dollar sign notation and assigning a result adds a new column. &gt; # add column for Kilometer per liter &gt; mtcars$kpl &lt;- mtcars$mpg/2.352 Doing the same with an existing variable updates the values in a column. &gt; # update to liters per 100 Kilometers &gt; mtcars$kpl &lt;- 100/mtcars$kpl To remove a variable, assign it NULL. &gt; # drop the kpl variable &gt; mtcars$kpl &lt;- NULL 4.5 Create strings from numbers You may have data that is numeric but that needs to be treated as a string. Python R The as.character() function takes a vector and converts it to string format. &gt; head(mtcars$am) [1] 1 1 1 0 0 0 &gt; head(as.character(mtcars$am)) [1] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; Note we just demonstrated conversion. To save the conversion we need to assign the result to the data frame. &gt; # add new string variable am_ch &gt; mtcars$am_ch &lt;- as.character(mtcars$am) &gt; head(mtcars$am_ch) [1] &quot;1&quot; &quot;1&quot; &quot;1&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; The factor() function can also be used to convert a numeric vector into a categorical variable. The result is not exactly a string, however. A factor is made of integers with character labels. Factors are useful for character data that have a fixed set of levels (eg, “grade 1,” grade 2”, etc) &gt; # convert to factor &gt; head(mtcars$am) [1] 1 1 1 0 0 0 &gt; head(factor(mtcars$am)) [1] 1 1 1 0 0 0 Levels: 0 1 &gt; # convert to factor with labels &gt; head(factor(mtcars$am, labels = c(&quot;automatic&quot;, &quot;manual&quot;))) [1] manual manual manual automatic automatic automatic Levels: automatic manual Again we just demonstrated factor conversion. To save the conversion we need to assign to the data frame. &gt; # create factor variable am_fac &gt; mtcars$am_fac &lt;- factor(mtcars$am, labels = c(&quot;automatic&quot;, &quot;manual&quot;)) &gt; head(mtcars$am_fac) [1] manual manual manual automatic automatic automatic Levels: automatic manual TODO: add zip code conversion using str_pad() (or base R option?) 4.6 Create numbers from strings String variables that ought to be numbers usually have some character data in the values such as units (eg, “4 cm”). To create numbers from strings it’s important to remove any character data that cannot be converted to a number. Python R The as.numeric() function will attempt to coerce strings to numeric type if possible. Any non-numeric values are coerced to NA. For demonstration, let’s say we have the following vector. &gt; weight &lt;- c(&quot;125 lbs.&quot;, &quot;132 lbs.&quot;, &quot;156 lbs.&quot;) The as.numeric() function returns all NA due to presence of character data. &gt; as.numeric(weight) Warning: NAs introduced by coercion [1] NA NA NA There are many ways to approach this. A common approach is to first remove the characters and then use as.numeric(). Below we use the sub function to find “lbs.” and replace with nothing. &gt; weightN &lt;- gsub(&quot;lbs.&quot;, &quot;&quot;, weight) &gt; as.numeric(weightN) [1] 125 132 156 The parse_number() function in the readr package can often take care of these situations automatically. &gt; readr::parse_number(weight) [1] 125 132 156 4.7 Change case How to change the case of strings. The most common case transformations are lower case, upper case, and title case. Python R The tolower() and toupper() functions convert case to lower and upper, respectively. &gt; names(mtcars) &lt;- toupper(names(mtcars)) &gt; names(mtcars) [1] &quot;MPG&quot; &quot;CYLINDERS&quot; &quot;DISP&quot; &quot;HP&quot; &quot;AXLE_RATIO&quot; &quot;WEIGHT&quot; &quot;QSEC&quot; &quot;ENGINE&quot; &quot;AM&quot; &quot;GEAR&quot; &quot;CARB&quot; &quot;AM_CH&quot; [13] &quot;AM_FAC&quot; &gt; names(mtcars) &lt;- tolower(names(mtcars)) &gt; names(mtcars) [1] &quot;mpg&quot; &quot;cylinders&quot; &quot;disp&quot; &quot;hp&quot; &quot;axle_ratio&quot; &quot;weight&quot; &quot;qsec&quot; &quot;engine&quot; &quot;am&quot; &quot;gear&quot; &quot;carb&quot; &quot;am_ch&quot; [13] &quot;am_fac&quot; The stringr package provides a convenient title case conversion function, str_to_title(), which capitalizes the first letter of each string. &gt; stringr::str_to_title(names(mtcars)) [1] &quot;Mpg&quot; &quot;Cylinders&quot; &quot;Disp&quot; &quot;Hp&quot; &quot;Axle_ratio&quot; &quot;Weight&quot; &quot;Qsec&quot; &quot;Engine&quot; &quot;Am&quot; &quot;Gear&quot; &quot;Carb&quot; &quot;Am_ch&quot; [13] &quot;Am_fac&quot; 4.8 Drop duplicate rows How to find and drop duplicate elements. Python R The duplicated() function “determines which elements of a vector or data frame are duplicates of elements with smaller subscripts.” (from ?duplicated) &gt; # create data frame with duplicate rows &gt; mtcars2 &lt;- rbind(mtcars[1:3,1:6], mtcars[1,1:6]) &gt; # last row is duplicate of first &gt; mtcars2 mpg cylinders disp hp axle_ratio weight 1 21.0 6 160 110 3.90 2.620 2 21.0 6 160 110 3.90 2.875 3 22.8 4 108 93 3.85 2.320 4 21.0 6 160 110 3.90 2.620 The duplicated() function returns a logical vector. TRUE indicates a row is a duplicate of a previous row. &gt; # last row is duplicate &gt; duplicated(mtcars2) [1] FALSE FALSE FALSE TRUE The TRUE/FALSE vector can be used to extract or drop duplicate rows. Since TRUE in indexing brackets will keep a row, we can use ! to negate the logicals and keep those that are “NOT TRUE” &gt; # drop the duplicate and update the data frame &gt; mtcars3 &lt;- mtcars2[!duplicated(mtcars2),] &gt; mtcars3 mpg cylinders disp hp axle_ratio weight 1 21.0 6 160 110 3.90 2.620 2 21.0 6 160 110 3.90 2.875 3 22.8 4 108 93 3.85 2.320 &gt; # extract and investigate the duplicate row &gt; mtcars2[duplicated(mtcars2),] mpg cylinders disp hp axle_ratio weight 4 21 6 160 110 3.9 2.62 The anyDuplicated() function returns the row number of duplicate rows. &gt; anyDuplicated(mtcars2) [1] 4 4.9 Randomly sample rows How to take a random sample of rows from a data frame. The sample is usually either a fixed size or a proportion. Python R There are many ways to sample rows from a data frame in R. The dplyr package provides a convenience function, slice_sample(), for taking either a fixed sample size or a proportion. &gt; # sample 5 rows from mtcars &gt; dplyr::slice_sample(mtcars, n = 5) mpg cylinders disp hp axle_ratio weight qsec engine am gear carb am_ch am_fac 1 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 0 automatic 2 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 1 manual 3 13.3 8 350.0 245 3.73 3.840 15.41 0 0 3 4 0 automatic 4 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 0 automatic 5 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 0 automatic &gt; # sample 20% of rows from mtcars &gt; dplyr::slice_sample(mtcars, prop = 0.20) mpg cylinders disp hp axle_ratio weight qsec engine am gear carb am_ch am_fac 1 15.2 8 275.8 180 3.07 3.78 18.00 0 0 3 3 0 automatic 2 14.3 8 360.0 245 3.21 3.57 15.84 0 0 3 4 0 automatic 3 18.1 6 225.0 105 2.76 3.46 20.22 1 0 3 1 0 automatic 4 15.0 8 301.0 335 3.54 3.57 14.60 0 1 5 8 1 manual 5 26.0 4 120.3 91 4.43 2.14 16.70 0 1 5 2 1 manual 6 15.5 8 318.0 150 2.76 3.52 16.87 0 0 3 2 0 automatic To sample with replacement, set replace = TRUE. The base R functions sample() and runif() can be combined to sample sizes or approximate proportions. &gt; # sample 5 rows from mtcars &gt; # get random row numbers &gt; i &lt;- sample(nrow(mtcars), size = 5) &gt; # use i to select rows &gt; mtcars[i,] mpg cylinders disp hp axle_ratio weight qsec engine am gear carb am_ch am_fac 18 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 1 manual 29 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 1 manual 31 15.0 8 301.0 335 3.54 3.570 14.60 0 1 5 8 1 manual 21 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 0 automatic 25 19.2 8 400.0 175 3.08 3.845 17.05 0 0 3 2 0 automatic &gt; # sample about 20% of rows from mtcars &gt; # generate random values on range of [0,1] &gt; i &lt;- runif(nrow(mtcars)) &gt; # use i &lt; 0.20 logical vector to &gt; # select rows that correspond to TRUE &gt; mtcars[i &lt; 0.20,] mpg cylinders disp hp axle_ratio weight qsec engine am gear carb am_ch am_fac 10 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 0 automatic 13 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 0 automatic 14 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 0 automatic 16 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 0 automatic 22 15.5 8 318.0 150 2.76 3.520 16.87 0 0 3 2 0 automatic 28 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 1 manual 29 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 1 manual The random sample will change every time the code is run. To always generate the same “random” sample, use the set.seed() function with any positive integer. &gt; # always get the same random sample &gt; set.seed(123) &gt; i &lt;- runif(nrow(mtcars)) &gt; mtcars[i &lt; 0.20,] mpg cylinders disp hp axle_ratio weight qsec engine am gear carb am_ch am_fac 6 18.1 6 225.0 105 2.76 3.46 20.22 1 0 3 1 0 automatic 15 10.4 8 472.0 205 2.93 5.25 17.98 0 0 3 4 0 automatic 18 32.4 4 78.7 66 4.08 2.20 19.47 1 1 4 1 1 manual 30 19.7 6 145.0 175 3.62 2.77 15.50 0 1 5 6 1 manual "],["combine-reshape-and-merge.html", "Chapter 5 Combine, Reshape and Merge 5.1 Combine rows 5.2 Combine columns 5.3 Reshaping data 5.4 Merge/Join", " Chapter 5 Combine, Reshape and Merge This chapter looks at various strategies for combining, reshaping, and merging data. 5.1 Combine rows Combining rows may be thought of as “stacking” rectangular data structures. Python R The rbind() function “binds” rows. It takes two or more objects. To row bind data frames the column names must match, otherwise an error is returned. If columns being stacked have differing variable types, the values will be coerced according to logical &lt; integer &lt; double &lt; complex &lt; character. (E.g., if you stack a set of rows with type logical in column J on a set of rows with type character in column J, the output will have column J as type character.) &gt; d1 &lt;- data.frame(x = 4:6, y = letters[1:3]) &gt; d2 &lt;- data.frame(x = 3:1, y = letters[4:6]) &gt; rbind(d1, d2) x y 1 4 a 2 5 b 3 6 c 4 3 d 5 2 e 6 1 f See also the bind_rows() function in the dplyr package. 5.2 Combine columns Combining columns may be thought of as setting rectangular data structures next to each other. Python R The cbind() function “binds” columns. It takes two or more objects. To column bind data frames, the number of rows must match; otherwise, the object with fewer rows will have rows “recycled” (if possible) or an error will be returned. &gt; d1 &lt;- data.frame(x = 10:13, y = letters[1:4]) &gt; d2 &lt;- data.frame(x = c(23,34,45,44)) &gt; cbind(d1, d2) x y x 1 10 a 23 2 11 b 34 3 12 c 45 4 13 d 44 &gt; # example of recycled rows (d1 is repeated twice) &gt; d1 &lt;- data.frame(x = 10:13, y = letters[1:4]) &gt; d2 &lt;- data.frame(x = c(23,34,45,44,99,99,99,99)) &gt; cbind(d1, d2) x y x 1 10 a 23 2 11 b 34 3 12 c 45 4 13 d 44 5 10 a 99 6 11 b 99 7 12 c 99 8 13 d 99 See also the bind_cols() function in the dplyr package. 5.3 Reshaping data The next two sections discuss how to reshape data from wide to long and from long to wide. “Wide” data are structured such that multiple values associated with a given unit (e.g., a person, a cell culture, etc.) are placed in the same row: name time_1_score time_2_score 1 larry 3 0 2 moe 6 3 3 curly 2 1 Long data, conversely, are structured such that all values are contained in one column, with another column identifying what value is given in any particular row (“time 1,” “time 2,” etc.): id time score 1 larry 1 3 2 larry 2 0 3 moe 1 6 4 moe 2 3 5 curly 1 2 6 curly 2 1 Shifting between these two data formats is often necessary for implementing certain statistical techniques or representing data with particular visualizations. 5.3.1 Wide to long Python R In base R, the reshape() function can take data from wide to long or long to wide. The tidyverse also provides reshaping functions: pivot_longer() and pivot_wider(). The tidyverse functions have a degree of intuitiveness and usability that may make them the go-to reshaping tools for many R users. We give examples below using both base R and tidyverse. Say we begin with a wide data frame, df_wide, that looks like this: id sex wk1 wk2 wk3 1 1 m 16 7 15 2 2 m 12 19 10 3 3 f 8 15 7 To lengthen a data frame using reshape(), a user provides arguments specifying the columns that identify values’ origins (person, cell culture, etc.), the columns containing values to be lengthened, and the desired names for output columns in long data: &gt; df_long &lt;- reshape(df_wide, + direction = &#39;long&#39;, + idvar = c(&#39;id&#39;, &#39;sex&#39;), # column(s) that uniquely identifies/y each row + varying = c(&#39;wk1&#39;, &#39;wk2&#39;, &#39;wk3&#39;), # variables that contain the values to be lengthened + v.names = &#39;val&#39;, # desired name of column in long data that will contain values + timevar = &#39;week&#39;) # desired name of column in long data that will identify each value&#39;s context &gt; df_long id sex week val 1.m.1 1 m 1 16 2.m.1 2 m 1 12 3.f.1 3 f 1 8 1.m.2 1 m 2 7 2.m.2 2 m 2 19 3.f.2 3 f 2 15 1.m.3 1 m 3 15 2.m.3 2 m 3 10 3.f.3 3 f 3 7 The tidyverse function for taking data from wide to long is pivot_longer(). To lengthen df_wide using pivot_longer(), a user would write: &gt; library(tidyverse) &gt; df_long_PL &lt;- pivot_longer(df_wide, + cols = -c(&#39;id&#39;, &#39;sex&#39;), # columns that contain the values to be lengthened (can use -c() to negate variables) + names_to = &#39;week&#39;, # desired name of column in long data that will identify each value&#39;s context + values_to = &#39;val&#39;) # desired name of column in long data that will contain values &gt; df_long_PL # A tibble: 9 × 4 id sex week val &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; 1 1 m wk1 16 2 1 m wk2 7 3 1 m wk3 15 4 2 m wk1 12 5 2 m wk2 19 6 2 m wk3 10 7 3 f wk1 8 8 3 f wk2 15 9 3 f wk3 7 pivot_longer() is particularly useful (a) when dealing with wide data that contain multiple sets of repeated measures in each row that need to be lengthened separately (e.g., two monthly height measurements and two monthly weight measurements for each person) and (b) when column names and/or column values in the long data need to be extracted from column names of the wide data using regular expressions. For example, say we begin with a wide data frame, animals_wide, in which every row contains two values for each of two different measures: animal lives_in_water jan_playfulness feb_playfulness jan_excitement feb_excitement 1 dolphin TRUE 6.0 5.5 7.0 7.0 2 porcupine FALSE 3.5 4.5 3.5 3.5 3 capybara FALSE 4.0 5.0 4.0 4.0 pivot_longer() can be used to convert this data frame to a long format where there is one column for each of the measures, playfulness and excitement: &gt; animals_long_1 &lt;- pivot_longer(animals_wide, + cols = -c(&#39;animal&#39;, &#39;lives_in_water&#39;), + names_to = c(&#39;month&#39;, &#39;.value&#39;), # &quot;.value&quot; is placeholder for strings that will be extracted from wide column names + names_pattern = &#39;(.+)_(.+)&#39;) # specify structure of wide column names with regex from which long column names will be extracted &gt; animals_long_1 # A tibble: 6 × 5 animal lives_in_water month playfulness excitement &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; 1 dolphin TRUE jan 6 7 2 dolphin TRUE feb 5.5 7 3 porcupine FALSE jan 3.5 3.5 4 porcupine FALSE feb 4.5 3.5 5 capybara FALSE jan 4 4 6 capybara FALSE feb 5 4 Alternatively, pivot_longer() can be used to convert this data frame to a long format where there is one column containing all the playfulness and excitement values: &gt; animals_long_2 &lt;- pivot_longer(animals_wide, + cols = -c(&#39;animal&#39;, &#39;lives_in_water&#39;), + names_to = c(&#39;month&#39;, &#39;measure&#39;), + names_pattern = &#39;(.+)_(.+)&#39;, + values_to = &#39;val&#39;) &gt; animals_long_2 # A tibble: 12 × 5 animal lives_in_water month measure val &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; 1 dolphin TRUE jan playfulness 6 2 dolphin TRUE feb playfulness 5.5 3 dolphin TRUE jan excitement 7 4 dolphin TRUE feb excitement 7 5 porcupine FALSE jan playfulness 3.5 6 porcupine FALSE feb playfulness 4.5 7 porcupine FALSE jan excitement 3.5 8 porcupine FALSE feb excitement 3.5 9 capybara FALSE jan playfulness 4 10 capybara FALSE feb playfulness 5 11 capybara FALSE jan excitement 4 12 capybara FALSE feb excitement 4 5.3.2 Long to wide Python R Say we begin with a long data frame, df_long, that looks like this: &gt; df_long id sex week val 1.m.1 1 m 1 16 2.m.1 2 m 1 12 3.f.1 3 f 1 8 1.m.2 1 m 2 7 2.m.2 2 m 2 19 3.f.2 3 f 2 15 1.m.3 1 m 3 15 2.m.3 2 m 3 10 3.f.3 3 f 3 7 To take data from long to wide with base R’s reshape(), a user would write: &gt; df_wide &lt;- reshape(df_long, + direction = &#39;wide&#39;, + idvar = c(&#39;id&#39;, &#39;sex&#39;), # column(s) that determine which rows should be grouped together in the wide data + v.names = &#39;val&#39;, # column containing values to widen + timevar = &#39;week&#39;, # column from which resulting wide column names are pulled + sep = &#39;_&#39;) # the `sep` argument allows a user to specify how the contents of `timevar` should be joined with the name of the `v.names` variable to form wide column names &gt; df_wide id sex val_1 val_2 val_3 1.m.1 1 m 16 7 15 2.m.1 2 m 12 19 10 3.f.1 3 f 8 15 7 The tidyverse function for taking data from long to wide is pivot_wider(). To widen df_long using pivot_longer(), a user would write: &gt; library(tidyverse) &gt; df_wide_PW &lt;- pivot_wider(df_long, + id_cols = c(&#39;id&#39;, &#39;sex&#39;), + values_from = &#39;val&#39;, + names_from = &#39;week&#39;, + names_prefix = &#39;week_&#39;) # `names_prefix` specifies a string to paste in front of the contents of &#39;week&#39; in the resulting wide column names &gt; df_wide_PW # A tibble: 3 × 5 id sex week_1 week_2 week_3 &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; 1 1 m 16 7 15 2 2 m 12 19 10 3 3 f 8 15 7 pivot_wider() offers a lot of usability when widening relatively complicated long data structures. For example, say we want to widen both of the long versions of the animals data frame created above. To widen the version of the long data that has a column for each of the measures (playfulness and excitement): &gt; animals_long_1 # A tibble: 6 × 5 animal lives_in_water month playfulness excitement &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; 1 dolphin TRUE jan 6 7 2 dolphin TRUE feb 5.5 7 3 porcupine FALSE jan 3.5 3.5 4 porcupine FALSE feb 4.5 3.5 5 capybara FALSE jan 4 4 6 capybara FALSE feb 5 4 &gt; animals_wide &lt;- pivot_wider(animals_long_1, + id_cols = c(&#39;animal&#39;, &#39;lives_in_water&#39;), + values_from = c(&#39;playfulness&#39;, &#39;excitement&#39;), + names_from = &#39;month&#39;, + names_glue = &#39;{month}_{.value}&#39;) # `names_glue` allow for customization of wide column names based &gt; animals_wide # A tibble: 3 × 6 animal lives_in_water jan_playfulness feb_playfulness jan_excitement feb_excitement &lt;chr&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 dolphin TRUE 6 5.5 7 7 2 porcupine FALSE 3.5 4.5 3.5 3.5 3 capybara FALSE 4 5 4 4 To widen the version of the long data that has one column containing all the values of playfulness and excitement together: &gt; animals_long_2 # A tibble: 12 × 5 animal lives_in_water month measure val &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; 1 dolphin TRUE jan playfulness 6 2 dolphin TRUE feb playfulness 5.5 3 dolphin TRUE jan excitement 7 4 dolphin TRUE feb excitement 7 5 porcupine FALSE jan playfulness 3.5 6 porcupine FALSE feb playfulness 4.5 7 porcupine FALSE jan excitement 3.5 8 porcupine FALSE feb excitement 3.5 9 capybara FALSE jan playfulness 4 10 capybara FALSE feb playfulness 5 11 capybara FALSE jan excitement 4 12 capybara FALSE feb excitement 4 &gt; animals_wide &lt;- pivot_wider(animals_long_2, + id_cols = c(&#39;animal&#39;, &#39;lives_in_water&#39;), + values_from = &#39;val&#39;, + names_from = c(&#39;month&#39;, &#39;measure&#39;), + names_sep = &#39;_&#39;) &gt; animals_wide # A tibble: 3 × 6 animal lives_in_water jan_playfulness feb_playfulness jan_excitement feb_excitement &lt;chr&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 dolphin TRUE 6 5.5 7 7 2 porcupine FALSE 3.5 4.5 3.5 3.5 3 capybara FALSE 4 5 4 4 5.4 Merge/Join 5.4.1 Left Join Python R 5.4.2 Right Join Python R 5.4.3 Inner Join Python R 5.4.4 Outer Join Python R "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
