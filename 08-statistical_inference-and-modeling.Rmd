# Statistical Inference and Modeling

```{r,echo=FALSE}
knitr::opts_chunk$set(comment = NA, prompt = TRUE, collapse = TRUE)
```

This chapter looks at performing common statistical analyses. It does not pretend to be comprehensive. The focus is on implementation using Python and R. Good statistical practice is more than knowing which function to use. At a minimum we recommend reading the article, [Ten Simple Rules for Effective Statistical Practice](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004961) [@kass_caffo_davidian_meng_yu_reid_2016].

## Comparing group means

Many research studies compare mean values of some quantity of interest between two or more groups. A t test analyzes two group means. An Analysis of Variance, or ANOVA, analyzes three or more group means. Both the t test and ANOVA are special cases of a linear model.

To demonstrate the t test, we examine fictitious data on 15 scores between two groups of subjects. The "control" group was tested as-is while the "treated" group experienced a particular intervention. Of interest is (1) whether or not the mean scores differ meaningfully between the treated and control groups, and (2) if they do differ, how are they different?

To demonstrate the ANOVA test, we use data from _The Analysis of Biological Data (3rd ed)_[@whitlock_schluter_2020] on the mass of pine cones (in grams) from three different environments in North America. Of interest is (1) whether or not the mean mass of pine cones differ meaningfully between the three locations, and (2) if they do differ, how are they different?

We usually assess the first question in each scenario with a hypothesis test and p-value. The null hypothesis is no difference between the means. The p-value is basically the probability of the observed differences between the groups (or more extreme differences) assuming the null hypothesis is true. A small p-value, traditionally less then 0.05, provides evidence against the null. For example, a p-value of 0.01 says there's a 1% chance of sampling data as different as this (or more different) if there really was no difference between the groups. Note that p-values don't tell you how two or more statistics differ. See [the ASA Statement on p-values](https://www.tandfonline.com/doi/full/10.1080/00031305.2016.1154108#_i28).

We assess the second question in each scenario by calculating confidence intervals on the difference in means. This is more informative than a p-value. A confidence interval gives us information on the uncertainty, direction and magnitude of a difference in means. For example, a 95% confidence interval of [2, 15] tells us the data is consistent with a difference anywhere between 2 and 15 and that the mean of one group appears to be at least 2 units larger than the mean of the other group. Note that a 95% confidence interval does not mean there is a 95% probability that the true value is in the interval. The confidence interval either captured the true value or it did not. We don't know. However the _process_ of calculating the confidence interval works roughly 95% of the time.


```{r echo=FALSE}
# toy data for t-test
set.seed(1)
s1 <- round(rnorm(n = 15, mean = 80, sd = 4))
s2 <- round(rnorm(n = 15, mean = 85, sd = 4))
ch8_d1 <- data.frame(
  score = c(s1, s2),
  group = rep(c("control", "treated"), each = 15)
)
rm(s1,s2)

# data from The Analysis of Biological Data, 3 ed. 
# Ch 15 assignment problem, p. 498
ch8_d2 <- data.frame(mass = c(9.6, 9.4, 8.9, 8.8, 8.5, 8.2,
                              6.8, 6.6, 6.0, 5.7, 5.3,
                              6.7, 6.4, 6.2, 5.7, 5.6),
                     location = rep(c("1", "2", "3"),
                                    times = c(6, 5, 5)))

```



```{python echo = FALSE}
ch8_d1 = r.ch8_d1
ch8_d2 = r.ch8_d2
```



#### Python {-}

**t-test**

Our data is available as a **Pandas** dataframe. It's small enough to view in its entirety.

```{python}
ch8_d1
```

The usual way to perform a t test in Python is via the `ttest_ind()` function available in the **scipy.stats** package.

```{python}
from scipy import stats

```

The `ttest_ind()` function performs a t test between two arrays (or columns of a data frame) specified with the `a` and `b` arguments, respectively. By default the function assumes equal population variances. By setting the `equal_var` parameter to False we can relax that assumption and run Welch's t test, which is the default in R. The function returns the test statistic and p-value.


```{python}
stats.ttest_ind(a = ch8_d1.query('group == "control"')['score'], 
                b = ch8_d1.query('group == "treated"')['score'],
                equal_var=False)
```


**ANOVA**

Our data is available as a **Pandas** dataframe. It's small enough to view in its entirety.

```{python}
ch8_d2
```

The usual way to perform an ANOVA test in Python is via the `f_oneway()` function, also available in the **scipy.stats** package.

The `f_oneway()` function performs an ANOVA between two or more arrays (or columns of a data frame) specified as inputs to the function. The function returns the test statistic and p-value.

```{python}
stats.f_oneway(ch8_d2.query('location == "1"')['mass'], 
               ch8_d2.query('location == "2"')['mass'],
               ch8_d2.query('location == "3"')['mass'])
```


#### R {-}



**t-test**

The `str()` function allows to take a quick look at the data frame `ch8_d1`. One column contains the scores, the other column indicates which group the subject was in (control vs treated).

```{r}
str(ch8_d1)
```

A stripchart is one of many ways to visualize numeric data between two groups. Here we use the base R function `stripchart()`. The formula `score ~ group` says to plot score by group. The `las = 1` argument says to rotate the y-axis labels. The `method = "jitter"` arguments says to randomly scatter the points vertically so they don't overplot. It appears the treated group had higher scores.

```{r}
stripchart(score ~ group, data = ch8_d1, las = 1, method = "jitter")
```

To calculate the means between the two groups we can use the `aggregate()` function. Again the formula `score ~ group` says to aggregate score by group. We specify `mean` so that we calculate the mean between the two groups. Some other functions we could specify include `median`, `sd`, or `sum`. The sample mean of the treated group is about 5 points higher than the control group.

```{r}
aggregate(score ~ group, data = ch8_d1, mean)
```

Is this difference meaningful? What if we took more samples? Would each sample result in similar differences in the means? A t test attempts to answer this. 

The `t.test()` function accommodates formula notation allowing us to specify that we want to calculate mean score by group.

```{r}
t.test(score ~ group, data = ch8_d1)
```

The p-value of 0.0015 is small, providing good evidence that the difference in means we witnessed reflects a real difference in the population. The confidence interval on the difference in means tells us the data is consistent with a difference between -7 and -2. It appears we can expect the control group to score at least 2 points lower than the treated group. 


**ANOVA**

The `str()` function allows to take a quick look at the data frame `ch8_d2`. One column contains the mass of the pine cones, the other column indicates which location the pine cone was found.


```{r}
str(ch8_d2)
```

Again we use a stripchart to visualize the three groups of data. It appears the treated group had higher scores. It appears the pine cones in location 1 have a higher mass.

```{r}
stripchart(mass ~ location, data = ch8_d2, las = 1, method = "jitter")
```

To calculate the means between the three groups we can use the `aggregate()` function. Again the formula `mass ~ location` says to aggregate mass by location. We specify `mean` so that we calculate the mean between the three groups. 

```{r}
aggregate(mass ~ location, data = ch8_d2, mean)
```

Is this difference meaningful? ANOVA attempts to answer this. 

The `aov()` function carries out the ANOVA test and also accommodates formula notation. It's usually preferable to save the ANOVA result into an object and call `summary()` on the object.

```{r}
aov1 <- aov(mass ~ location, data = ch8_d2)
summary(aov1)
```

The small p-value of 0.0000007 provides strong evidence that the difference in means we witnessed reflects a real difference in the population.

Unlike the `t.test()` output, the `aov()` summary does not provide confidence intervals on differences in means. That's because there are many kinds of differences we might want to assess. A common and easy procedure is Tukey's Honestly Significant Differences (HSD), which computes differences between all possible pairs and returns adjusted p-values and confidence intervals to account for the multiple comparisons. Base R provides the `TukeyHSD()` function for this task. Call it on the ANOVA object.

```{r}
TukeyHSD(aov1)
```

The difference in means between locations 2 and 1 (2 - 1) and locations 3 and 1 (3 - 1) are about -2.8. The difference in means between locations 3 and 2 (3 - 2) is inconclusive. It seems to be small but we're not sure if the difference is positive or negative.

Both the t-test and ANOVA are special cases of the linear model (ie, regression). We can obtain the same results, presented in different ways, using the `lm()` function. See the Linear Modeling section.

```{r eval=FALSE}
m1 <- lm(score ~ group, data = ch8_d1)
summary(m1)
m2 <- lm(mass ~ location, data = ch8_d2)
summary(m2)
```


## Comparing group proportions

Comparing the proportions of two or more groups to see if or how they differ. 


#### Python {-}


#### R {-}

## linear modeling

Analyzing if or how the variability a numeric variable depends on one or more predictor variables.

#### Python {-}


#### R {-}



## Logistic regression

Analyzing if or how the variability of a binary variable depends on one or more predictor variables.

#### Python {-}


#### R {-}
