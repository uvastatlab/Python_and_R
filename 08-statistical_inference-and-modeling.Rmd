# Selected Topics in Statistical Inference

```{r,echo=FALSE}
knitr::opts_chunk$set(comment = NA, prompt = TRUE, collapse = TRUE)
```

This chapter looks at performing selected statistical analyses. It is not comprehensive. The focus is on implementation using Python and R. Good statistical practice is more than knowing which function to use. At a minimum we recommend reading the article, [Ten Simple Rules for Effective Statistical Practice](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004961) [@kass_caffo_davidian_meng_yu_reid_2016].

## Comparing group means

Many research studies compare mean values of some quantity of interest between two or more groups. A t test analyzes two group means. An Analysis of Variance, or ANOVA, analyzes three or more group means. Both the t test and ANOVA are special cases of a linear model.

To demonstrate the t test, we examine fictitious data on 15 scores between two groups of subjects. The "control" group was tested as-is while the "treated" group experienced a particular intervention. Of interest is (1) whether or not the mean scores differ meaningfully between the treated and control groups, and (2) if they do differ, how are they different?

To demonstrate the ANOVA test, we use data from _The Analysis of Biological Data (3rd ed)_[@whitlock_schluter_2020] on the mass of pine cones (in grams) from three different environments in North America. Of interest is (1) whether or not the mean mass of pine cones differ meaningfully between the three locations, and (2) if they do differ, how are they different?

We usually assess the first question in each scenario with a hypothesis test and p-value. The null hypothesis is no difference between the means. The p-value is the probability of the observed differences between the groups (or more extreme differences) assuming the null hypothesis is true. A small p-value, traditionally less then 0.05, provides evidence against the null. For example, a p-value of 0.01 says there's a 1% chance of sampling data as different as this (or more different) if there really was no difference between the groups. Note that p-values don't tell you how two or more statistics differ. See [the ASA Statement on p-values](https://www.tandfonline.com/doi/full/10.1080/00031305.2016.1154108#_i28).

We assess the second question in each scenario by calculating confidence intervals on the difference in means. This is more informative than a p-value. A confidence interval gives us information on the uncertainty, direction and magnitude of a difference in means. For example, a 95% confidence interval of [2, 15] tells us the data is consistent with a difference anywhere between 2 and 15 and that the mean of one group appears to be at least 2 units larger than the mean of the other group. Note that a 95% confidence interval does not mean there is a 95% probability that the true value is in the interval. The confidence interval either captured the true value or it did not. We don't know. However the _process_ of calculating the confidence interval works roughly 95% of the time.


```{r echo=FALSE}
# toy data for t-test
set.seed(1)
s1 <- round(rnorm(n = 15, mean = 80, sd = 4))
s2 <- round(rnorm(n = 15, mean = 85, sd = 4))
ch8_d1 <- data.frame(
  score = c(s1, s2),
  group = rep(c("control", "treated"), each = 15)
)
rm(s1,s2)

# data from The Analysis of Biological Data, 3 ed. 
# Ch 15 assignment problem, p. 498
ch8_d2 <- data.frame(mass = c(9.6, 9.4, 8.9, 8.8, 8.5, 8.2,
                              6.8, 6.6, 6.0, 5.7, 5.3,
                              6.7, 6.4, 6.2, 5.7, 5.6),
                     location = rep(c("1", "2", "3"),
                                    times = c(6, 5, 5)))

```



```{python echo = FALSE}
ch8_d1 = r.ch8_d1
ch8_d2 = r.ch8_d2
```



#### Python {-}

**t-test**

Our data is available as a **Pandas** dataframe. It's small enough to view in its entirety.

```{python}
ch8_d1
```


A stripchart is one of many ways to visualize numeric data between two groups. Here we use the seaborn function `stripplot()`. It appears the treated group had higher scores.

```{python }
import seaborn as sns
import matplotlib.pyplot as plt
sns.stripplot(x="score", y="group", data=ch8_d1)
plt.show()
```


One way to perform a t test in Python is via the `CompareMeans()` function and its associated methods available in the **statsmodels** package. Below we import **statsmodels.stats.api** as "sms".

```{python}
import statsmodels.stats.api as sms
```

We first extract the data we want to compare as pandas Series.

```{python}
d_control = ch8_d1.query('group == "control"')['score']
d_treated = ch8_d1.query('group == "treated"')['score']
```

Next we create Descriptive statistics objects using the `DescrStatsW()` function.

```{python}
control = sms.DescrStatsW(d_control)
treated = sms.DescrStatsW(d_treated)
```

Descriptive statistics objects have attributes such as `mean` and `std` (standard deviation). Below we print the mean and standard deviation of each group. We also round the standard deviation to three decimal places and place a line break before printing the standard deviation.

```{python}
print("control mean:", control.mean, "\ncontrol std:", round(control.std, 3))
print("treated mean:", treated.mean, "\ntreated std:", round(treated.std, 3))
```

Next we create a CompareMeans means object using the `CompareMeans()` function. The required inputs are Descriptive statistics objects. We save the result as "ttest".

```{python}
ttest = sms.CompareMeans(control, treated)
```

Now we can use various methods with the "ttest" object. To see the result of a two sample t test assuming unequal variances, along with a confidence interval on the differences, use the `summary` method with `usevar='unequal'`. 

```{python}
print(ttest.summary(usevar='unequal'))
```

The p-value of 0.001 is small, providing good evidence that the difference in means we witnessed reflects a real difference in the population. The confidence interval on the difference in means tells us the data is consistent with a difference between -7 and -2. It appears we can expect the control group to score at least 2 points lower than the treated group.


**ANOVA**

Our data is available as a **Pandas** dataframe. It's small enough to view in its entirety.

```{python}
ch8_d2
```

Again we use a stripchart to visualize the three groups of data. It appears the pine cones in location 1 have a higher mass.

```{python}
plt.clf()
sns.stripplot(x="mass", y="location", data=ch8_d2)
plt.show()
```



We can calculate means using the `groupby` and `mean` methods.

```{python}
ch8_d2['mass'].groupby(ch8_d2['location']).mean()
```

One way to perform an ANOVA test in Python is via the `anova_oneway()` function, also available in the **statsmodels** package.

The `anova_oneway()` function can perform an ANOVA on a pandas Dataframe with the first argument specifying the numeric data and the second argument the grouping variable. We also set `use_var='equal'` to replicate the R output below.

```{python}
sms.anova_oneway(ch8_d2.mass, ch8_d2.location, use_var='equal')
```

The small p-value of 0.0000007 provides strong evidence that the difference in means we witnessed reflects a real difference in the population.

A common follow-up to an ANOVA is Tukey's Honestly Significant Differences (HSD), which computes differences between all possible pairs and returns adjusted p-values and confidence intervals to account for the multiple comparisons. To carry this out in the **statsmodels** package, we need to first create a MultiComparison object using the `multicomp.MultiComparison()` function. Then we use the `tukeyhsd()` method to compare the means with corrected p-values.

```{python}
mc = sms.multicomp.MultiComparison(ch8_d2.mass, ch8_d2.location)
print(mc.tukeyhsd())
```

The difference in means between locations 2 and 1 (2 - 1) and locations 3 and 1 (3 - 1) are about -2.8. The difference in means between locations 3 and 2 (3 - 2) is inconclusive. It seems to be small but we're not sure if the difference is positive or negative.

#### R {-}



**t-test**

The `str()` function allows to take a quick look at the data frame `ch8_d1`. One column contains the scores, the other column indicates which group the subject was in (control vs treated).

```{r}
str(ch8_d1)
```

A stripchart is one of many ways to visualize numeric data between two groups. Here we use the base R function `stripchart()`. The formula `score ~ group` says to plot score by group. The `las = 1` argument says to rotate the y-axis labels. The `method = "jitter"` arguments says to randomly scatter the points vertically so they don't overplot. It appears the treated group had higher scores.

```{r}
stripchart(score ~ group, data = ch8_d1, las = 1, method = "jitter")
```

To calculate the means between the two groups we can use the `aggregate()` function. Again the formula `score ~ group` says to aggregate score by group. We specify `mean` so that we calculate the mean between the two groups. Some other functions we could specify include `median`, `sd`, or `sum`. The sample mean of the treated group is about 5 points higher than the control group.

```{r}
aggregate(score ~ group, data = ch8_d1, mean)
```

Is this difference meaningful? What if we took more samples? Would each sample result in similar differences in the means? A t test attempts to answer this. 

The `t.test()` function accommodates formula notation allowing us to specify that we want to calculate mean score by group.

```{r}
t.test(score ~ group, data = ch8_d1)
```

The p-value of 0.0015 is small, providing good evidence that the difference in means we witnessed reflects a real difference in the population. The confidence interval on the difference in means tells us the data is consistent with a difference between -7 and -2. It appears we can expect the control group to score at least 2 points lower than the treated group. 


**ANOVA**

The `str()` function allows to take a quick look at the data frame `ch8_d2`. One column contains the mass of the pine cones, the other column indicates which location the pine cone was found.


```{r}
str(ch8_d2)
```

Again we use a stripchart to visualize the three groups of data. It appears the pine cones in location 1 have a higher mass.

```{r}
stripchart(mass ~ location, data = ch8_d2, las = 1, method = "jitter")
```

To calculate the means between the three groups we can use the `aggregate()` function. Again the formula `mass ~ location` says to aggregate mass by location. We specify `mean` so that we calculate the mean between the three groups. 

```{r}
aggregate(mass ~ location, data = ch8_d2, mean)
```

Is this difference meaningful? ANOVA attempts to answer this. 

The `aov()` function carries out the ANOVA test and also accommodates formula notation. It's usually preferable to save the ANOVA result into an object and call `summary()` on the object.

```{r}
aov1 <- aov(mass ~ location, data = ch8_d2)
summary(aov1)
```

The small p-value of 0.0000007 provides strong evidence that the difference in means we witnessed reflects a real difference in the population.

Unlike the `t.test()` output, the `aov()` summary does not provide confidence intervals on differences in means. That's because there are many kinds of differences we might want to assess. A common and easy procedure is Tukey's Honestly Significant Differences (HSD), which computes differences between all possible pairs and returns adjusted p-values and confidence intervals to account for the multiple comparisons. Base R provides the `TukeyHSD()` function for this task. Call it on the ANOVA object.

```{r}
TukeyHSD(aov1)
```

The difference in means between locations 2 and 1 (2 - 1) and locations 3 and 1 (3 - 1) are about -2.8. The difference in means between locations 3 and 2 (3 - 2) is inconclusive. It seems to be small but we're not sure if the difference is positive or negative.


## Comparing group proportions

It is often of interest to compare proportions between two groups. Sometimes this is referred to as a two-sample proportion test. To demonstrate we use an exercise from the text _Introductory Statistics with R_ [@Dalgaard_2020] (p.154). We are told that 210 out of 747 patients died of Rocky Mountain spotted fever in the western United States. That's a proportion of `r round(210/747, 3)`. In the eastern United States, 122 out 661 patients died. That's a proportion of `r round(122/661, 3)`. Is the difference in proportions statistically significant? In other words, assuming there is no difference in the fatality rate between the two regions, is this difference in proportions surprising?


#### Python {-}


#### R {-}

A two-sample proportion test in R can be carried out with the `prop.test()` function. The first argument, `x`, is the number of "successes" or "occurrences" of some event for each group. The second argument, `n`, is the number of total trials for each group.

```{r}
prop.test(x = c(210, 122), n = c(747, 661))
```

The proportion of patients who died in the western US is about 0.28. The proportion who died in the eastern US is about 0.18. The small p-value says there is a very small chance of seeing a difference as large as this (or larger) if there really was no difference in the proportions. The confidence interval on the difference of proportions ranges from 0.05 to 0.14, indicating that this fever seems to kill at least 5% more patients in the western US.

Sometimes data is presented in a 2-way table with successes and failures. We can present the preceding data in a table as follows using the `matrix()` function. 

```{r}
fever <- matrix(c(210, 122,
                  747-210, 661-122), ncol = 2)
rownames(fever) <- c("western US", "eastern US")
colnames(fever) <- c("died", "lived")
fever
```

When the table is constructed in this fashion with "successes" in the first column and "failures" in the second column, we can feed the table directly to the `prop.test()` function. (Obviously "success" here means "experienced the event of interest".)

```{r}
prop.test(fever)
```

The chi-squared test statistic is reported as `X-squared = 17.612`. This is the same statistic reported if we ran a chi-squared test of association using the `chisq.test()` function. 

```{r}
chisq.test(fever)
```

This tests the null hypothesis of no association between location in the US and fatality of the fever. The result is identical to `prop.test()` output, however there is no indication of the nature of association.


## Linear modeling

Analyzing if or how the variability a numeric variable depends on one or more predictor variables.

#### Python {-}


#### R {-}



## Logistic regression

Analyzing if or how the variability of a binary variable depends on one or more predictor variables.

#### Python {-}


#### R {-}
